{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "# torch.manual_seed(0)\n",
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device to use for processing\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "data = pd.read_csv(\"datasets/train_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target variable\n",
    "X = data.drop(\"Price\", axis=1).values\n",
    "y = data[\"Price\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)#, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 1469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class HousePriceModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HousePriceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 128)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = HousePriceModel(input_size).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimization algorithm\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/500], Training Loss: 126484.2109, Validation Loss: 137071.1094\n",
      "Epoch [200/500], Training Loss: 119434.1406, Validation Loss: 131440.9688\n",
      "Epoch [300/500], Training Loss: 116391.5547, Validation Loss: 128946.9688\n",
      "Epoch [400/500], Training Loss: 113228.0938, Validation Loss: 126999.9297\n",
      "Epoch [500/500], Training Loss: 109219.4922, Validation Loss: 125144.8047\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    outputs = model(X_train_tensor)  # Forward pass on training set\n",
    "    train_loss = criterion(outputs, y_train_tensor.view(-1, 1))  # Compute training loss\n",
    "    train_loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor)  # Forward pass on validation set\n",
    "        val_loss = criterion(y_pred, y_test_tensor.view(-1, 1))  # Compute validation loss\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move tensors back to CPU\n",
    "y_pred = y_pred.cpu()\n",
    "y_test_tensor = y_test_tensor.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 125144.8047\n",
      "MSE: 47679283200.0000\n",
      "RMSE: 218355.8594\n",
      "VarScore: 0.7322\n"
     ]
    }
   ],
   "source": [
    "# Check model performance\n",
    "print(f'MAE: {metrics.mean_absolute_error(y_test_tensor.numpy(), y_pred.numpy()):.4f}')\n",
    "print(f'MSE: {metrics.mean_squared_error(y_test_tensor.numpy(), y_pred.numpy()):.4f}')\n",
    "print(f'RMSE: {metrics.mean_squared_error(y_test_tensor.numpy(), y_pred.numpy(), squared=False):.4f}')\n",
    "print(f'VarScore: {metrics.explained_variance_score(y_test_tensor.numpy(), y_pred.numpy()):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at: models/house_price_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model_path = \"models/house_price_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Model saved successfully at:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is trained on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check the device where the model parameters are located\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(\"Model is trained on GPU.\")\n",
    "else:\n",
    "    print(\"Model is trained on CPU.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
